{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/warry258/InvokeAI-v3.6.2/blob/main/%E2%80%9CColab_v3_6_2_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XRVqxiOY-Qn"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: center\">\n",
        "    <h1></h1>\n",
        "</div>\n",
        "<h1><center>Colab Notebook for InvokeAi v3.6.2</center></h1>\n",
        "\n",
        "<center>\n",
        "    <a href=\"https://www.patreon.com/huzaifaarshad\" title=\"My Patreon\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/Patreon_logomark.svg\" width=\"20\" height=\"20\"></a>\n",
        "   &nbsp;\n",
        "    <a href=\"https://github.com/i-huzaifa-arshad\" title=\"My GitHub\"><img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=\"20\" height=\"20\"></a>\n",
        "</center>\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "q5f-n5b-5VOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c8758e-866b-4af4-885d-0a14a80af0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **1. Connect Google Drive**\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown - If you have low storage in drive, skip this step and proceed to install InvokeAi in Colab Storage\n",
        "#@markdown - Please note once you restart runtime, you will lose all data, so download important files before closing the notebook\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XiOM2iy7DNWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d3befb-e7ba-4a15-ea73-aa27da238dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ” Done!\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **2. Install / Update InvokeAI**\n",
        "#@markdown ---\n",
        "#@markdown - Running this code will automatically create `InvokeAI-v3.6.2` folder and clone the repository in it, so no need to create a separate folder\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/gdrive/MyDrive\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/i-huzaifa-arshad/InvokeAI-v3.6.2\n",
        "clear_output()\n",
        "\n",
        "print('\\u2714 Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0664e2c1-3a82-4d51-b158-1cfc27837c65",
        "cellView": "form",
        "id": "SdhVbcC9DlnV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/InvokeAI-v3.6.2'\n",
            "/content/gdrive/MyDrive\n",
            "\u001b[1;32mInstalling dependencies...\n",
            "âœ” Done\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **3. Install Dependencies (Required)**\n",
        "#@markdown ---\n",
        "#@markdown - It takes about ~8-10 minutes to install the required dependencies\n",
        "#@markdown - In case you think it's not working, don't worry. Sit back and relax ðŸ˜‰\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%cd /content/InvokeAI-v3.6.2\n",
        "\n",
        "# # Add the directory of your cloned repository to sys.path\n",
        "import sys\n",
        "sys.path.append('/content/InvokeAI-v3.6.2')\n",
        "\n",
        "print('\u001b[1;32mInstalling dependencies...')\n",
        "\n",
        "# Installing requirements from Dependencies folder\n",
        "!pip install --upgrade pip setuptools > nul 2>&1\n",
        "!pip install --use-pep517 --upgrade --force-reinstall -r Dependencies/Requirements.txt > nul 2>&1\n",
        "!pip install -q -e . > nul 2>&1\n",
        "\n",
        "print ('\\u2714 Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23fb73f-2c8e-4d8e-d21d-0f2254354dae",
        "cellView": "form",
        "id": "h9blTI1JESu-"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/InvokeAI-v3.6.2'\n",
            "/content/gdrive/MyDrive\n",
            "\u001b[1;32mDownloading model(s)...\n",
            "âœ” Done\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **4-a. Model Download**\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown - Installing stable diffusion model (SD 1.5). If you want to install ControlNet and/or other models (SD XL, etc), click on the below path\n",
        "#@markdown - `/content/InvokeAI-v3.6.2/invokeai/configs/INITIAL_MODELS.yaml` and change `recommended: False` to `recommended: True`\n",
        "#@markdown - Installing SD 1.5 model will take about ~3-5 minutes. If you selected other models as well, it will take more time due to their size (or your internet speed)\n",
        "#@markdown - If you get `AttributeError: 'set' object has no attribute 'extend'` error, just delete the `GUI` folder from your drive and run the cell again\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%cd /content/InvokeAI-v3.6.2\n",
        "\n",
        "print('\u001b[1;32mDownloading model(s)...')\n",
        "\n",
        "!python /content/InvokeAI-v3.6.2/scripts/invokeai-model-install.py --root_dir /content/InvokeAI-v3.6.2/GUI --yes > /dev/null 2>&1\n",
        "\n",
        "print ('\\u2714 Done')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBObKQqMPbV1",
        "outputId": "935d3303-680f-4584-de28-80dec129dc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "5ARC8gvBoVMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62949cb1-9ee1-4cbc-83c0-a37c0e9195ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Downloaded! ðŸš€\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **4-b. Download Custom model (Optional)**\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown - Download a trained dreambooth `.ckpt model` or other desired models from `google drive` or `civitai.com`\n",
        "#@markdown - Just write desired `model name` and `model url` and it will automatically download the models in the required path\n",
        "#@markdown - You don't have to write model extension in `model_name` as it will automatically add it and save models like `model-name.ckpt` or `model-name.safetensors`\n",
        "#@markdown - If you get some error about model while running the InvokeAI, install the model using `model manager` inside InvokeAI Webui\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Ask the user for the model name\n",
        "model_name = \"LZ-16K+Optics_V2.0.safetensors\" # @param {type:\"string\"}\n",
        "\n",
        "model_link = \"/content/gdrive/MyDrive/Download/LZ-16K+Optics_V2.0.safetensors\" # @param {type:\"string\"}\n",
        "\n",
        "# Define the directory where the model will be saved\n",
        "model_dir = '/content/gdrive/MyDrive/InvokeAI-v3.6.2/GUI/models/sd-1/main'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Check if the URL is from Google Drive\n",
        "if \"drive.google.com\" in model_link:\n",
        "    # Add the .ckpt extension\n",
        "    model_filename = f\"{model_name}.ckpt\"\n",
        "\n",
        "    # Extract the file ID from the URL\n",
        "    file_id = model_link.split('/')[-2]\n",
        "\n",
        "    # Download the file from Google Drive\n",
        "    !gdown https://drive.google.com/uc?id={file_id} -O {os.path.join(model_dir, model_filename)}\n",
        "\n",
        "else:\n",
        "    # Add the .safetensors extension\n",
        "    model_filename = f\"{model_name}.safetensors\"\n",
        "\n",
        "    # Download the model\n",
        "    !wget -O {os.path.join(model_dir, model_filename)} \"{model_link}\"\n",
        "\n",
        "clear_output()\n",
        "print('Model Downloaded! ðŸš€')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall peft -y"
      ],
      "metadata": {
        "id": "9eGoMr7WUsyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d54a88c-a12a-43e6-bad1-ede8718b2736"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: peft 0.14.0\n",
            "Uninstalling peft-0.14.0:\n",
            "  Successfully uninstalled peft-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install peft==0.6.2"
      ],
      "metadata": {
        "id": "lQnwQ7I2Uzz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12907bb6-d650-4225-e53c-7519ffbefc46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft==0.6.2\n",
            "  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.6.2) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->peft==0.6.2) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.6.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.6.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.6.2) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.6.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.6.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.6.2) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.6.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.6.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.6.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.6.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.6.2) (2025.1.31)\n",
            "Downloading peft-0.6.2-py3-none-any.whl (174 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m156.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **6. Run InvokeAI**\n",
        "#@markdown - Launching InvokeAI Web UI via Ngrok\n",
        "#@markdown - The outputs will be saved in the `Outputs` folder under `/content/InvokeAI/GUI` path\n",
        "#@markdown - Create an account on [Ngrok](https://ngrok.com/), to get your `ngrok token`\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #### - Enter your [Ngrok Token](https://dashboard.ngrok.com/get-started/your-authtoken) here\n",
        "ngrok_token = \"2gmppDmqfMA2GX2uaAm74P5R7Jn_2Rf2EZc32UZdUZrQ8aZor\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "!pip install pyngrok\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "\n",
        "clear_output()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "id_rsa_file = \"/root/.ssh/id_rsa\"\n",
        "id_rsa_pub_file = \"/root/.ssh/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(\"/root/.ssh/\") / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "# Start the ngrok tunnel\n",
        "\n",
        "!ngrok authtoken {ngrok_token}\n",
        "ngrok_tunnel = ngrok.connect(9090)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "%cd /content/InvokeAI-v3.6.2/\n",
        "!python /content/InvokeAI-v3.6.2/scripts/invokeai-web.py --root /content/InvokeAI-v3.6.2/GUI\n"
      ],
      "metadata": {
        "id": "PynDFlNg9TFs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}